
# import cv2
# import torch
# import threading
# import time
# import numpy as np
# from ultralytics import YOLO

# # Check GPU
# if torch.cuda.is_available():
#     print("✅ GPU is available and will be used.")
# else:
#     print("❌ GPU not available. Running on CPU.")

# # Load YOLOv8 models
# ppe_model = YOLO("helmet_vest.pt")  # Helmet + Vest
# person_model = YOLO("yolo11s.pt")  # Person detection

# # RTSP stream or video file
# video_path = "rtsp://10.30.30.191:555/screenlive"
# #  "resource/video/200.mp4",#issue
#         # "resource/video/100.mp4",#go
#         # "resource/video/2024.mp4",#isue

#         # "resource/video/v5.mp4",#issue

#         # "resource/video/2021.mp4",#issue
        

#         # "resource/video/2024.mp4",
#         #  "resource/video/2002.mp4",
#         #  "resource/video/37.mp4",
#         # "F:\\PPE_DEV_ANU\\resource\\video\\57.mp4"# isssue
#         # "resource/video/30.mp4",
# # video_path = "resource/video/8.mp4"

# # Global shared frame variable
# frame = None
# ret = False
# stopped = False

# # RTSP frame reader in a separate thread
# def video_reader():
#     global frame, ret, stopped
#     cap = cv2.VideoCapture(video_path)
#     while not stopped:
#         ret, f = cap.read()
#         if ret:
#             frame = f
#         else:
#             print("❌ Failed to read frame.")
#             stopped = True
#     cap.release()

# # PPE classification
# def ppe_detector(person_image):
#     helmet = False
#     vest = False
#     res = ppe_model(person_image, conf=0.6)[0]
#     if res.boxes is not None:
#         class_ids = res.boxes.cls.cpu().numpy().astype(int)
#         for class_id in class_ids:
#             if class_id == 0:
#                 helmet = True
#             elif class_id == 1:
#                 vest = True

#     if helmet and vest:
#         return 1  # Safe
#     elif helmet:
#         return 2  # Only helmet
#     elif vest:
#         return 3  # Only vest
#     else:
#         return 4  # Unsafe

# # Start video thread
# thread = threading.Thread(target=video_reader, daemon=True)
# thread.start()

# # Inference loop
# CONF_THRESHOLD = 0.6

# while True:
#     if frame is None or not ret:
#         continue

#     current_frame = frame.copy()
#     current_frame = cv2.resize(current_frame, (1080, 700))
#     results = person_model(current_frame, conf=CONF_THRESHOLD)[0]
#     annotated = current_frame.copy()

#     if results.boxes is not None:
#         boxes = results.boxes.xyxy.cpu().numpy()
#         class_ids = results.boxes.cls.cpu().numpy().astype(int)

#         for box, class_id in zip(boxes, class_ids):
#             if class_id == 0:  # Person
#                 x1, y1, x2, y2 = map(int, box)
#                 person_crop = current_frame[y1:y2, x1:x2]
#                 ans = ppe_detector(person_crop)

#                 if ans == 1:
#                     color, label = (0, 255, 0), "Safe"
#                 elif ans == 2:
#                     color, label = (255, 255, 0), "Only Helmet"
#                 elif ans == 3:
#                     color, label = (0, 255, 255), "Only Vest"
#                 else:
#                     color, label = (0, 0, 255), "Unsafe"

#                 cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)
#                 cv2.putText(annotated, label, (x1, y1 - 10),
#                             cv2.FONT_HERSHEY_SIMPLEX, 0.6,   color, 2)

#     cv2.imshow("PPE Detection (Threaded)", annotated)

#     # Quit on 'q'
#     if cv2.waitKey(1) & 0xFF == ord('q'):
#         stopped = True
#         break

# cv2.destroyAllWindows()

# # import time
# # from ultralytics import YOLO
# # import cv2

# # # Load YOLOv8 model
# # model = YOLO("best.pt")  # Replace with your model path

# # # Load image
# # video_path = "rtsp://admin:Admin@123@10.30.30.49/1"
# # # video_path="resource/video/v6.mp4"
# # cap = cv2.VideoCapture(video_path)  # 0 for webcam, or path to a video file

# # while True:
# #     ret, frame = cap.read()
# #     if not ret:
# #         break

# #     results = model(frame, conf=0.4)
# #     result = results[0]
# #     annotated_frame = frame.copy()

# #     if result.boxes is not None and result.boxes.cls is not None:
       
# #         for box, cls_id, conf in zip(result.boxes.xyxy, result.boxes.cls, result.boxes.conf):
# #             class_id = int(cls_id)
            
# #             if class_id in [2, 6]:  # 2 = helmet, 6 = no_helmet
# #                 x1, y1, x2, y2 = map(int, box)
# #                 label = f"{model.names[class_id]}: {conf:.2f}"

# #                 # Set color: Green for helmet, Red for no_helmet
# #                 color = (0, 255, 0) if class_id == 2 else (0, 0, 255)

# #                 # Draw bounding box and label
# #                 cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)
# #                 cv2.putText(annotated_frame, label, (x1, y1 - 10),
# #                             cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)


# #     # Resize the annotated frame
# #     resized_frame = cv2.resize(annotated_frame, (780, 720))  # or any other size
# #     cv2.imshow("Detected Equipment (Resized)", resized_frame)
# #     time.sleep(0.001)

# #     if cv2.waitKey(1) & 0xFF == ord('q'):
# #         break

# # cap.release()
# # cv2.destroyAllWindows()

# from ultralytics import YOLO
# import cv2

# # Load your trained model
# model = YOLO("resourse/shoes_model.pt")  # Replace with your model path

# # RTSP stream URL
# rtsp_url = "rtsp://admin:Admin@123@10.30.30.49/1"  # Replace with your actual RTSP stream URL

# # Open the RTSP stream
# cap = cv2.VideoCapture(rtsp_url)

# if not cap.isOpened():
#     print("[ERROR] Cannot open RTSP stream.")
#     exit()

# while True:
#     ret, frame = cap.read()
#     if not ret:
#         print("[WARNING] Failed to grab frame.")
#         break

#     # Perform detection
#     results = model.predict(source=frame, conf=0.3, iou=0.5, imgsz=640, device=0, stream=False, verbose=False)

#     # Draw bounding boxes
#     for result in results:
#         boxes = result.boxes
#         for box in boxes:
#             x1, y1, x2, y2 = map(int, box.xyxy[0])
#             conf = float(box.conf[0])
#             cls_id = int(box.cls[0])
#             label = model.names[cls_id]

#             # Draw rectangle and label
#             cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
#             cv2.putText(frame, f'{label} {conf:.2f}', (x1, y1 - 10),
#                         cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

#     # Display the result
#     cv2.imshow("RTSP Shoes Detection", frame)

#     # Press 'q' to exit
#     if cv2.waitKey(1) == ord('q'):
#         break

# # Clean up
# cap.release()
# cv2.destroyAllWindows()

